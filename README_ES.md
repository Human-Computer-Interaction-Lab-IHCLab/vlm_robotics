# Sistema h√≠brido informado por simetr√≠a basado en LLM/VLM para manipulaci√≥n rob√≥tica educativa

**[üìò Read this in English / Leer en ingl√©s](README.md)**

Este repositorio contiene un sistema reproducible que integra un **modelo multimodal de lenguaje (LLM/VLM)** como sensor sem√°ntico con **control determinista basado en cinem√°tica inversa**, aplicado a un brazo rob√≥tico **Yahboom DOFBOT**.

El proyecto demuestra c√≥mo la **razonamiento generativo** puede combinarse con algoritmos deterministas para ejecutar tareas de manipulaci√≥n de objetos, aplicando la **simetr√≠a como principio de dise√±o** en lugar de una caracter√≠stica aprendida.

---

## üåê Arquitectura general

- **Lado del robot (`MainRobot.py`):**  
  Inicia el brazo, captura una imagen de la c√°mara y levanta dos servidores TCP:
  - **Servidor de imagen** en el puerto **6103**  
  - **Servidor de comandos** en el puerto **6104**

- **Lado del cliente (`RuedaColorEs.py`):**  
  Descarga la imagen, la env√≠a junto con un mensaje de texto al modelo multimodal de OpenAI (`gpt-4o`) y, seg√∫n la respuesta (por ejemplo, ‚Äúabajo derecha‚Äù), env√≠a los comandos de movimiento correspondientes al servidor del robot.

---

## ‚öôÔ∏è Requisitos

**Hardware**
- Brazo rob√≥tico DOFBOT (o equivalente de 6 GDL)
- C√°mara USB o CSI conectada al robot

**Software**
- Python 3.8 o superior
- Librer√≠as:
  ```bash
  pip install opencv-python openai
